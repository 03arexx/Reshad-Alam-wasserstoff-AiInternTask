# Chatbot Document Query

A FastAPI-based application that allows users to upload documents (PDF or `.txt`), process them, and query their content using Open AI's `gpt-4o` model. The app extracts text from documents, stores embeddings in ChromaDB, and identifies themes using natural language processing. A simple HTML/JavaScript frontend provides a user-friendly interface to interact with the backend API.

## Features

- **Document Upload**: Upload PDF or `.txt` files via `/api/upload`.
- **Query Processing**: Query document content via `/api/query`, with responses and themes generated by Open AI's `gpt-4o` model.
- **Vector Storage**: Uses ChromaDB to store document embeddings for efficient search.
- **Theme Identification**: Identifies common themes across documents using NLP.
- 

## Tech Stack

- **Backend**: FastAPI (`fastapi==0.115.0`), Python 3.11
- **NLP**: Open AI (`langchain-openai==0.2.3`), Sentence Transformers (`sentence-transformers==2.7.0`)
- **Vector DB**: ChromaDB (`chromadb==0.5.3`)
- **Dependencies**: `pytesseract==0.3.10`, `pdf2image==1.16.3`, `torch==2.4.1`, `transformers==4.39.3`

## Project Structure

```
chatbot_theme_identifier/
├── backend/
│   ├── app/
│   │   ├── core/
│   │   │   ├── config.py         # Configuration and environment variables
│   │   │   ├── theme_identifier.py # Theme identification logic
│   │   │   ├── vector_db.py      # Vector storage and search with ChromaDB
│   │   ├── models/
│   │   │   ├── document.py       # Pydantic models for API requests/responses
│   │   ├── services/
│   │   │   ├── document_service.py # Document processing logic
│   │   │   ├── query_service.py  # Query processing logic
│   │   ├── main.py               # FastAPI application entry point
│   ├── requirements.txt          # Backend dependencies
├── venv/                         # Virtual environment
├── .env                          # Environment variables (e.g., OPENAI_API_KEY)
```

## Prerequisites

- **Python 3.11**: Ensure Python 3.11 is installed.
- **System Dependencies**:
  - **Tesseract**: For OCR (PDF text extraction). Install from [here](https://github.com/UB-Mannheim/tesseract/wiki).
  - **Poppler**: For PDF processing. Install from [here](https://github.com/oschwartz10612/poppler-windows).
  - **Microsoft Visual C++ Redistributable**: Required for some Python packages. Install from [here](https://aka.ms/vs/17/release/vc_redist.x64.exe).
- **Open AI API Key**: Sign up at [Open AI](https://platform.openai.com/signup) and get an API key.

## Setup Instructions

### 1. Clone the Repository (if applicable)
If you're using version control, clone the repository:
```bash
git clone <repository-url>
cd chatbot_theme_identifier
```

### 2. Set Up the Virtual Environment
Create and activate a virtual environment:
```bash
python -m venv venv
venv\Scripts\activate  # On Windows
# source venv/bin/activate  # On macOS/Linux
```

### 3. Install Backend Dependencies
Install the required Python packages:
```bash
pip install -r backend\requirements.txt
```

### 4. Configure Environment Variables
Create a `.env` file in the project root and add your Open AI API key:
```bash
echo OPENAI_API_KEY=your_openai_api_key > .env
echo DATABASE_PATH=documents.db >> .env
```
Replace `your_openai_api_key` with your actual Open AI API key.

### 5. Run the Backend
Start the FastAPI application:
```bash
uvicorn backend.app.main:app --reload
```
The backend will run at `http://127.0.0.1:8000`. The frontend will also be served at this URL.


## Usage

### Upload Documents
1. In the "Upload Documents" section, select one or more PDF or `.txt` files.
2. Click "Upload" to process the files.
3. Note the document IDs returned (e.g., `uuid1`).

### Query Documents
1. In the "Query Documents" section, enter a query (e.g., "What is the main theme?").
2. Optionally, enter document IDs (comma-separated) from the upload step.
3. Click "Query" to get responses and themes extracted from the documents.

### API Endpoints
- **POST /api/upload**: Upload documents (PDF or `.txt`). Returns a list of document IDs.
  - Example: `curl -X POST "http://127.0.0.1:8000/api/upload" -F "files=@test.pdf"`
- **POST /api/query**: Query documents. Expects a JSON body with `query` (required) and `doc_ids` (optional).
  - Example: `curl -X POST "http://127.0.0.1:8000/api/query" -H "Content-Type: application/json" -d "{\"query\": \"What is the main theme?\"}"`
- **GET /api/documents**: List all uploaded documents.
  - Example: `curl "http://127.0.0.1:8000/api/documents"`

## Troubleshooting

- **500 Internal Server Error**:
  - Check the terminal logs for detailed errors.
  - Ensure Tesseract and Poppler are installed.
  - Verify your `OPENAI_API_KEY` in `.env`.
- **422 Unprocessable Entity** on `/api/query`:
  - Ensure the request body matches the expected format: `{"query": "your query", "doc_ids": ["id1", "id2"]}`.
- **405 Method Not Allowed**:
  - Use `POST` for `/api/upload` and `/api/query`. The frontend handles this automatically.
- **Embedding Errors**:
  - If `tolist()` errors occur, ensure `transformers==4.39.3` and `numpy==1.26.4` are installed.
  - Check logs for the embedding type: `INFO:__main__:Query embedding type: ...`.

## Development Notes

- **Backend**: The backend uses FastAPI with ChromaDB for vector storage and Open AI for NLP tasks.
- **Dependencies**: Ensure compatibility between `sentence-transformers==2.7.0`, `transformers==4.39.3`, and `torch==2.4.1`.

## Future Improvements

- Add support for more file types (e.g., `.docx`).
- Improve theme extraction with custom prompts.
- Implement response caching for faster queries.

## Contact

For issues or contributions, please contact [your-email@example.com] or open an issue on the repository.
